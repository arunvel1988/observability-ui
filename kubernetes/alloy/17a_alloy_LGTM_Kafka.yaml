###############################################################################

apiVersion: apps/v1
kind: Deployment
metadata:
  name: alloy
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: alloy
  template:
    metadata:
      labels:
        app: alloy
    spec:
      containers:
        - name: alloy
          image: grafana/alloy:v1.10.0
          args:
            - "run"
            - "--server.http.listen-addr=0.0.0.0:12345"
            - "--stability.level=experimental"
            - "--storage.path=/var/lib/alloy/data"
            - "/etc/alloy/config.alloy"
          ports:
            - containerPort: 12345
              name: http
            - containerPort: 4317
              name: otlp-grpc
            - containerPort: 4318
              name: otlp-http
          volumeMounts:
            # Alloy config
            - name: alloy-config
              mountPath: /etc/alloy

            # Aiven Kafka TLS certs
            - name: kafka-tls
              mountPath: /etc/kafka
              readOnly: true

      volumes:
        # Alloy config
        - name: alloy-config
          configMap:
            name: alloy-config

        # Kafka TLS Secret
        - name: kafka-tls
          secret:
            secretName: aiven-kafka-tls

#####################################
---
apiVersion: v1
kind: Service
metadata:
  name: alloy
  namespace: logging
spec:
  selector:
    app: alloy
  ports:
    - name: http
      port: 12345
      targetPort: 12345
      protocol: TCP
    - name: otlp-grpc
      port: 4317
      targetPort: 4317
      protocol: TCP
    - name: otlp-http
      port: 4318
      targetPort: 4318
      protocol: TCP
  type: ClusterIP
##########################################################################################
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: logging
data:
  config.alloy: |
  
    otelcol.receiver.otlp "default" {
      grpc {
        endpoint = "0.0.0.0:4317"
      }

      http {
        endpoint = "0.0.0.0:4318"
      }

      output {
        logs    = [otelcol.processor.batch.logs_ingest.input]
        traces  = [otelcol.processor.batch.traces_ingest.input]
        metrics = [otelcol.processor.batch.metrics_ingest.input]
      }
    }

 
    otelcol.processor.batch "logs_ingest" {
      output {
        logs = [otelcol.exporter.kafka.logs.input]
      }
    }

    otelcol.processor.batch "traces_ingest" {
      output {
        traces = [otelcol.exporter.kafka.traces.input]
      }
    }

    otelcol.processor.batch "metrics_ingest" {
      output {
        metrics = [otelcol.exporter.kafka.metrics.input]
      }
    }

    // =====================================================
    // 3. KAFKA EXPORTERS (produce)
    // =====================================================
    otelcol.exporter.kafka "logs" {
      brokers  = ["arunvel1988-kafka-arunvel1988.e.aivencloud.com:14253"]
      topic    = "otel-logs"
      encoding = "otlp_proto"

      tls {
        insecure  = false
        ca_file   = "/etc/kafka/ca.pem"
        cert_file = "/etc/kafka/service.cert"
        key_file  = "/etc/kafka/service.key"
      }
    }

    otelcol.exporter.kafka "traces" {
      brokers  = ["arunvel1988-kafka-arunvel1988.e.aivencloud.com:14253"]
      topic    = "otel-traces"
      encoding = "otlp_proto"

      tls {
        insecure  = false
        ca_file   = "/etc/kafka/ca.pem"
        cert_file = "/etc/kafka/service.cert"
        key_file  = "/etc/kafka/service.key"
      }
    }

    otelcol.exporter.kafka "metrics" {
      brokers  = ["arunvel1988-kafka-arunvel1988.e.aivencloud.com:14253"]
      topic    = "otel-metrics"
      encoding = "otlp_proto"

      tls {
        insecure  = false
        ca_file   = "/etc/kafka/ca.pem"
        cert_file = "/etc/kafka/service.cert"
        key_file  = "/etc/kafka/service.key"
      }
    }

    // =====================================================
    // 4. KAFKA RECEIVERS (consume)
    // =====================================================
    otelcol.receiver.kafka "logs" {
      brokers  = ["arunvel1988-kafka-arunvel1988.e.aivencloud.com:14253"]
      topics   = ["otel-logs"]
      encoding = "otlp_proto"

      tls {
        insecure  = false
        ca_file   = "/etc/kafka/ca.pem"
        cert_file = "/etc/kafka/service.cert"
        key_file  = "/etc/kafka/service.key"
      }

      output {
        logs = [otelcol.processor.batch.logs_export.input]
      }
    }

    otelcol.receiver.kafka "traces" {
      brokers  = ["arunvel1988-kafka-arunvel1988.e.aivencloud.com:14253"]
      topics   = ["otel-traces"]
      encoding = "otlp_proto"

      tls {
        insecure  = false
        ca_file   = "/etc/kafka/ca.pem"
        cert_file = "/etc/kafka/service.cert"
        key_file  = "/etc/kafka/service.key"
      }

      output {
        traces = [otelcol.processor.batch.traces_export.input]
      }
    }

    otelcol.receiver.kafka "metrics" {
      brokers  = ["arunvel1988-kafka-arunvel1988.e.aivencloud.com:14253"]
      topics   = ["otel-metrics"]
      encoding = "otlp_proto"

      tls {
        insecure  = false
        ca_file   = "/etc/kafka/ca.pem"
        cert_file = "/etc/kafka/service.cert"
        key_file  = "/etc/kafka/service.key"
      }

      output {
        metrics = [otelcol.processor.batch.metrics_export.input]
      }
    }

    // =====================================================
    // 5. BATCH (after Kafka)
    // =====================================================
    otelcol.processor.batch "logs_export" {
      output {
        logs = [otelcol.exporter.loki.default.input]
      }
    }

    otelcol.processor.batch "traces_export" {
      output {
        traces = [otelcol.exporter.otlp.tempo.input]
      }
    }

    otelcol.processor.batch "metrics_export" {
      output {
        metrics = [otelcol.exporter.prometheus.mimir.input]
      }
    }

    // =====================================================
    // 6. BACKENDS
    // =====================================================
    otelcol.exporter.loki "default" {
      forward_to = [loki.write.default.receiver]
    }

    loki.write "default" {
      endpoint {
        url = "http://loki:3100/loki/api/v1/push"
      }
    }

    otelcol.exporter.otlp "tempo" {
      client {
        endpoint = "http://tempo:4317"
        tls {
          insecure = true
        }
      }
    }

    otelcol.exporter.prometheus "mimir" {
      forward_to = [prometheus.remote_write.mimir.receiver]
    }

    prometheus.remote_write "mimir" {
      endpoint {
        url = "http://mimir:9009/api/v1/push"
      }
    }
####################################################################################
